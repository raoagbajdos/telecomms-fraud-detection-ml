#!/usr/bin/env python3
"""
Test script to simulate the weekly GitHub Actions training workflow.
This script mimics what the GitHub Actions workflow does to ensure everything works.
"""

import os
import subprocess
import sys
from pathlib import Path

def main():
    """Test the weekly training workflow locally."""
    
    print("ğŸ§ª Testing Weekly Model Training Workflow")
    print("=" * 50)
    
    # Change to project directory
    project_dir = Path(__file__).parent
    os.chdir(project_dir)
    
    # Step 1: Create necessary directories
    print("ğŸ“ Creating necessary directories...")
    os.makedirs("models", exist_ok=True)
    os.makedirs("logs", exist_ok=True)
    os.makedirs("data/processed", exist_ok=True)
    print("âœ… Directories created")
    
    # Step 2: Run the test pipeline to generate model.pkl
    print("\nğŸ¤– Running model training pipeline...")
    try:
        # Use the test pipeline which is known to work
        result = subprocess.run([
            sys.executable, "test_pipeline.py"
        ], capture_output=True, text=True, check=True)
        
        print("âœ… Pipeline completed successfully")
        if result.stdout:
            print("Pipeline output:")
            print(result.stdout[-500:])  # Last 500 chars
            
    except subprocess.CalledProcessError as e:
        print(f"âŒ Pipeline failed: {e}")
        print(f"Error output: {e.stderr}")
        return False
    
    # Step 3: Validate model output
    print("\nğŸ“Š Validating model output...")
    
    # Check for standard model.pkl
    if not os.path.exists('models/model.pkl'):
        print("âŒ Standard model.pkl file not found!")
        return False
    print("âœ… Standard model.pkl found")
    
    # Test model loading
    try:
        import pickle
        with open('models/model.pkl', 'rb') as f:
            model_data = pickle.load(f)
            print(f"âœ… Model loaded successfully: {type(model_data)}")
        
        # Get model size
        model_size = os.path.getsize('models/model.pkl') / (1024*1024)  # MB
        print(f"ğŸ“ Model size: {model_size:.2f} MB")
        
    except Exception as e:
        print(f"âŒ Failed to load model: {e}")
        return False
    
    # Step 4: Generate training report
    print("\nğŸ“‹ Generating training report...")
    try:
        from datetime import datetime
        import json
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'test_run': True,
            'model_file': 'model.pkl',
            'model_size_mb': round(os.path.getsize('models/model.pkl') / (1024*1024), 2),
            'python_version': f"{sys.version_info.major}.{sys.version_info.minor}",
            'trigger': 'local_test',
            'status': 'success'
        }
        
        with open('models/test_training_report.json', 'w') as f:
            json.dump(report, f, indent=2)
            
        print("âœ… Training report generated")
        print("Report content:")
        print(json.dumps(report, indent=2))
        
    except Exception as e:
        print(f"âŒ Failed to generate report: {e}")
        return False
    
    print("\nğŸ‰ Weekly training workflow test completed successfully!")
    print("\nFiles generated:")
    print(f"  - models/model.pkl ({os.path.getsize('models/model.pkl')} bytes)")
    print("  - models/test_training_report.json")
    
    print("\nğŸ’¡ This confirms that the GitHub Actions weekly workflow will work correctly!")
    print("   The workflow is scheduled to run every Sunday at 2 AM UTC.")
    print("   You can also trigger it manually from the GitHub Actions tab.")
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
